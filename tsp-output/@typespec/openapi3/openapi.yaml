openapi: 3.0.0
info:
  title: OpenAI API
  version: 2.0.0
tags:
  - name: OpenAI
paths:
  /audio/transcriptions:
    post:
      tags:
        - OpenAI
      operationId: createTranscription
      summary: Transcribes audio into the input language.
      parameters: []
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateTranscriptionResponse'
      requestBody:
        required: true
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/CreateTranscriptionRequest'
  /audio/translations:
    post:
      tags:
        - OpenAI
      operationId: createTranslation
      summary: Transcribes audio into the input language.
      parameters: []
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateTranslationResponse'
      requestBody:
        required: true
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/CreateTranslationRequest'
  /chat/completions:
    post:
      tags:
        - OpenAI
      operationId: createChatCompletion
      parameters: []
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateChatCompletionResponse'
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateChatCompletionRequest'
      x-oaiMeta:
        name: Create chat completion
        group: chat
        returns: >-
          Returns a [chat completion](/docs/api-reference/chat/object) object,
          or a streamed sequence of

          [chat completion chunk](/docs/api-reference/chat/streaming) objects if
          the request is streamed.
        path: create
        examples:
          - title: No streaming
            request:
              curl: |-
                curl https://api.openai.com/v1/chat/completions \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "VAR_model_id",
                  "messages": [
                    {
                      "role": "system",
                      "content": "You are a helpful assistant."
                    },
                    {
                      "role": "user",
                      "content": "Hello!"
                    }
                  ]
              python: |-
                import os
                import openai
                openai.api_key = os.getenv("OPENAI_API_KEY")

                completion = openai.ChatCompletion.create(
                  model="VAR_model_id",
                  messages=[
                    {"role": "system", "content": "You are a helpful assistant."},
                    {"role": "user", "content": "Hello!"}
                  ]
                )

                print(completion.choices[0].message)
              node.js: |-
                import OpenAI from "openai";

                const openai = new OpenAI();

                async function main() {
                  const completion = await openai.chat.completions.create({
                    messages: [{ role: "system", content: "string" }],
                    model: "VAR_model_id",
                  });

                  console.log(completion.choices[0]);
                }

                main();
            response: |-
              {
                "id": "chatcmpl-123",
                "object": "chat.completion",
                "created": 1677652288,
                "model": "gpt-3.5-turbo-0613",
                "choices": [{
                  "index": 0,
                  "message": {
                    "role": "assistant",
                    "content": "

              Hello there, how may I assist you today?",
                  },
                  "finish_reason": "stop"
                }],
                "usage": {
                  "prompt_tokens": 9,
                  "completion_tokens": 12,
                  "total_tokens": 21
                }
              }
          - title: Streaming
            request:
              curl: |-
                curl https://api.openai.com/v1/chat/completions \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "VAR_model_id",
                  "messages": [
                    {
                      "role": "system",
                      "content": "You are a helpful assistant."
                    },
                    {
                      "role": "user",
                      "content": "Hello!"
                    }
                  ],
                  "stream": true
                }'
              python: |-
                import os
                import openai
                openai.api_key = os.getenv("OPENAI_API_KEY")

                completion = openai.ChatCompletion.create(
                  model="VAR_model_id",
                  messages=[
                    {"role": "system", "content": "You are a helpful assistant."},
                    {"role": "user", "content": "Hello!"}
                  ],
                  stream=True
                )

                for chunk in completion:
                  print(chunk.choices[0].delta)
              node.js: |-
                import OpenAI from "openai";

                const openai = new OpenAI();

                async function main() {
                  const completion = await openai.chat.completions.create({
                    model: "VAR_model_id",
                    messages: [
                      {"role": "system", "content": "You are a helpful assistant."},
                      {"role": "user", "content": "Hello!"}
                    ],
                    stream: true,
                  });

                  for await (const chunk of completion) {
                    console.log(chunk.choices[0].delta.content);
                  }
                }

                main();
            response: |-
              {
                "id": "chatcmpl-123",
                "object": "chat.completion.chunk",
                "created": 1677652288,
                "model": "gpt-3.5-turbo",
                "choices": [{
                  "index": 0,
                  "delta": {
                    "content": "Hello",
                  },
                  "finish_reason": "stop"
                }]
              }
  /completions:
    post:
      tags:
        - OpenAI
      operationId: createCompletion
      parameters: []
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateCompletionResponse'
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateCompletionRequest'
  /edits:
    post:
      tags:
        - OpenAI
      operationId: createEdit
      parameters: []
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateEditResponse'
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateEditRequest'
      deprecated: true
  /embeddings:
    post:
      tags:
        - OpenAI
      operationId: createEmbedding
      summary: Creates an embedding vector representing the input text.
      parameters: []
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateEmbeddingResponse'
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateEmbeddingRequest'
  /files:
    get:
      tags:
        - OpenAI
      operationId: listFiles
      summary: Returns a list of files that belong to the user's organization.
      parameters: []
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListFilesResponse'
    post:
      tags:
        - OpenAI
      operationId: createFile
      summary: Returns a list of files that belong to the user's organization.
      parameters: []
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/OpenAIFile'
      requestBody:
        required: true
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/CreateFileRequest'
  /files/files/{file_id}:
    post:
      tags:
        - OpenAI
      operationId: retrieveFile
      summary: Returns information about a specific file.
      parameters:
        - name: file_id
          in: path
          required: true
          description: The ID of the file to use for this request
          schema:
            type: string
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/OpenAIFile'
    delete:
      tags:
        - OpenAI
      operationId: deleteFile
      summary: Delete a file
      parameters:
        - name: file_id
          in: path
          required: true
          description: The ID of the file to use for this request
          schema:
            type: string
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteFileResponse'
  /files/files/{file_id}/content:
    get:
      tags:
        - OpenAI
      operationId: downloadFile
      summary: Returns the contents of the specified file
      parameters:
        - name: file_id
          in: path
          required: true
          description: The ID of the file to use for this request
          schema:
            type: string
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                type: string
  /fine_tuning/jobs:
    post:
      operationId: FineTuningJobs_createFineTuningJob
      parameters: []
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FineTuningJob'
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateFineTuningJobRequest'
    get:
      operationId: FineTuningJobs_listPaginatedFineTuningJobs
      parameters: []
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListPaginatedFineTuningJobsResponse'
  /fine_tuning/jobs/{fine_tuning_job_id}:
    get:
      operationId: FineTuningJobsResource_retrieveFineTuningJob
      parameters:
        - name: fine_tuning_job_id
          in: path
          required: true
          schema:
            type: string
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FineTuningJob'
  /fine_tuning/jobs/{fine_tuning_job_id}/cancel:
    post:
      operationId: FineTuningJobsResource_cancelFineTuningJob
      parameters:
        - name: fine_tuning_job_id
          in: path
          required: true
          schema:
            type: string
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FineTuningJob'
  /fine_tuning/jobs/{fine_tuning_job_id}/events:
    get:
      operationId: FineTuningJobsResource_listFineTuningEvents
      parameters:
        - name: fine_tuning_job_id
          in: path
          required: true
          schema:
            type: string
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListFineTuningJobEventsResponse'
  /images/edits:
    post:
      tags:
        - OpenAI
      operationId: createImageEdit
      summary: >-
        Creates an edited or extended image given an original image and a
        prompt.
      parameters: []
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ImagesResponse'
      requestBody:
        required: true
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/CreateImageEditRequest'
  /images/generations:
    post:
      tags:
        - OpenAI
      operationId: createImage
      summary: Creates an image given a prompt
      parameters: []
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ImagesResponse'
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateImageRequest'
  /images/variations:
    post:
      tags:
        - OpenAI
      operationId: createImageVariation
      summary: >-
        Creates an edited or extended image given an original image and a
        prompt.
      parameters: []
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ImagesResponse'
      requestBody:
        required: true
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/CreateImageVariationRequest'
components:
  schemas:
    ChatCompletionFunctionCallOption:
      type: object
      properties:
        name:
          type: string
          description: The name of the function to call.
      required:
        - name
    ChatCompletionFunctionParameters:
      type: object
      additionalProperties: {}
    ChatCompletionFunctions:
      type: object
      properties:
        name:
          type: string
          description: >-
            The name of the function to be called. Must be a-z, A-Z, 0-9, or
            contain underscores and

            dashes, with a maximum length of 64.
        description:
          type: string
          description: >-
            A description of what the function does, used by the model to choose
            when and how to call the

            function.
        parameters:
          allOf:
            - $ref: '#/components/schemas/ChatCompletionFunctionParameters'
          description: >-
            The parameters the functions accepts, described as a JSON Schema
            object. See the

            [guide](/docs/guides/gpt/function-calling) for examples, and the

            [JSON Schema
            reference](https://json-schema.org/understanding-json-schema/) for
            documentation

            about the format.\n\nTo describe a function that accepts no
            parameters, provide the value

            `{\"type\": \"object\", \"properties\": {}}`.
      required:
        - name
        - parameters
    ChatCompletionRequestMessage:
      type: object
      properties:
        role:
          type: string
          enum:
            - system
            - user
            - assistant
            - function
          description: >-
            The role of the messages author. One of `system`, `user`,
            `assistant`, or `function`.
        content:
          type: string
          nullable: true
          description: >-
            The contents of the message. `content` is required for all messages,
            and may be null for

            assistant messages with function calls.
        name:
          type: string
          description: >-
            The name of the author of this message. `name` is required if role
            is `function`, and it

            should be the name of the function whose response is in the
            `content`. May contain a-z,

            A-Z, 0-9, and underscores, with a maximum length of 64 characters.
        function_call:
          type: object
          properties:
            name:
              type: string
              description: The name of the function to call.
            arguments:
              type: string
              description: >-
                The arguments to call the function with, as generated by the
                model in JSON format. Note that

                the model does not always generate valid JSON, and may
                hallucinate parameters not defined by

                your function schema. Validate the arguments in your code before
                calling your function.
          description: >-
            The name and arguments of a function that should be called, as
            generated by the model.
          required:
            - name
            - arguments
      required:
        - role
        - content
    ChatCompletionResponseMessage:
      type: object
      properties:
        role:
          type: string
          enum:
            - system
            - user
            - assistant
            - function
          description: The role of the author of this message.
        content:
          type: string
          nullable: true
          description: The contents of the message.
        function_call:
          type: object
          properties:
            name:
              type: string
              description: The name of the function to call.
            arguments:
              type: string
              description: >-
                The arguments to call the function with, as generated by the
                model in JSON format. Note that

                the model does not always generate valid JSON, and may
                hallucinate parameters not defined by

                your function schema. Validate the arguments in your code before
                calling your function.
          description: >-
            The name and arguments of a function that should be called, as
            generated by the model.
          required:
            - name
            - arguments
      required:
        - role
        - content
    CompletionUsage:
      type: object
      properties:
        prompt_tokens:
          type: integer
          format: int64
          description: Number of tokens in the prompt.
        completion_tokens:
          type: integer
          format: int64
          description: Number of tokens in the generated completion
        total_tokens:
          type: integer
          format: int64
          description: Total number of tokens used in the request (prompt + completion).
      description: Usage statistics for the completion request.
      required:
        - prompt_tokens
        - completion_tokens
        - total_tokens
    CreateChatCompletionRequest:
      type: object
      properties:
        model:
          anyOf:
            - type: string
            - type: string
              enum:
                - gpt4
                - gpt-4-0314
                - gpt-4-0613
                - gpt-4-32k
                - gpt-4-32k-0314
                - gpt-4-32k-0613
                - gpt-3.5-turbo
                - gpt-3.5-turbo-16k
                - gpt-3.5-turbo-0301
                - gpt-3.5-turbo-0613
                - gpt-3.5-turbo-16k-0613
          description: >-
            ID of the model to use. See the [model endpoint
            compatibility](/docs/models/model-endpoint-compatibility)

            table for details on which models work with the Chat API.
          x-oaiTypeLabel: string
        messages:
          type: array
          items:
            $ref: '#/components/schemas/ChatCompletionRequestMessage'
          description: >-
            A list of messages comprising the conversation so far.

            [Example Python
            code](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_format_inputs_to_ChatGPT_models.ipynb).
          minItems: 1
        functions:
          type: array
          items:
            $ref: '#/components/schemas/ChatCompletionFunctions'
          description: A list of functions the model may generate JSON inputs for.
          minItems: 1
          maxItems: 128
        function_call:
          anyOf:
            - type: string
              enum:
                - none
                - auto
            - $ref: '#/components/schemas/ChatCompletionFunctionCallOption'
          description: >-
            Controls how the model responds to function calls. "none" means the
            model does not call a

            function, and responds to the end-user. "auto" means the model can
            pick between an end-user or

            calling a function.  Specifying a particular function via `{"name":\
            "my_function"}` forces the

            model to call that function. "none" is the default when no functions
            are present. "auto" is the

            default if functions are present.
        temperature:
          oneOf:
            - $ref: '#/components/schemas/Temperature'
          nullable: true
          description: >-
            What sampling temperature to use, between 0 and 2. Higher values
            like 0.8 will make the output

            more random, while lower values like 0.2 will make it more focused
            and deterministic.


            We generally recommend altering this or `top_p` but not both.
        top_p:
          oneOf:
            - $ref: '#/components/schemas/TopP'
          nullable: true
          description: >-
            An alternative to sampling with temperature, called nucleus
            sampling, where the model considers

            the results of the tokens with top_p probability mass. So 0.1 means
            only the tokens comprising

            the top 10% probability mass are considered.


            We generally recommend altering this or `temperature` but not both.
        'n':
          oneOf:
            - $ref: '#/components/schemas/N'
          nullable: true
          description: >-
            How many completions to generate for each prompt.

            **Note:** Because this parameter generates many completions, it can
            quickly consume your token

            quota. Use carefully and ensure that you have reasonable settings
            for `max_tokens` and `stop`.
        max_tokens:
          oneOf:
            - $ref: '#/components/schemas/MaxTokens'
          nullable: true
          description: >-
            The maximum number of [tokens](/tokenizer) to generate in the
            completion.


            The token count of your prompt plus `max_tokens` cannot exceed the
            model's context length.

            [Example Python
            code](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb)

            for counting tokens.
        stop:
          anyOf:
            - type: string
            - $ref: '#/components/schemas/StopSequences'
          nullable: true
          description: Up to 4 sequences where the API will stop generating further tokens.
        presence_penalty:
          oneOf:
            - $ref: '#/components/schemas/Penalty'
          nullable: true
          description: >-
            Number between -2.0 and 2.0. Positive values penalize new tokens
            based on whether they appear

            in the text so far, increasing the model's likelihood to talk about
            new topics.


            [See more information about frequency and presence
            penalties.](/docs/guides/gpt/parameter-details)
        frequency_penalty:
          oneOf:
            - $ref: '#/components/schemas/Penalty'
          nullable: true
          description: >-
            Number between -2.0 and 2.0. Positive values penalize new tokens
            based on their existing

            frequency in the text so far, decreasing the model's likelihood to
            repeat the same line

            verbatim.


            [See more information about frequency and presence
            penalties.](/docs/guides/gpt/parameter-details)
        logit_bias:
          type: object
          additionalProperties:
            type: integer
            format: int64
          nullable: true
          description: >-
            Modify the likelihood of specified tokens appearing in the
            completion.

            Accepts a json object that maps tokens (specified by their token ID
            in the tokenizer) to an

            associated bias value from -100 to 100. Mathematically, the bias is
            added to the logits

            generated by the model prior to sampling. The exact effect will vary
            per model, but values

            between -1 and 1 should decrease or increase likelihood of
            selection; values like -100 or 100

            should result in a ban or exclusive selection of the relevant token.
          x-oaiTypeLabel: map
        user:
          allOf:
            - $ref: '#/components/schemas/User'
          description: >-
            A unique identifier representing your end-user, which can help
            OpenAI to monitor and detect

            abuse. [Learn
            more](/docs/guides/safety-best-practices/end-user-ids).
        stream:
          type: boolean
          nullable: true
          description: >-
            If set, partial message deltas will be sent, like in ChatGPT. Tokens
            will be sent as data-only

            [server-sent
            events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)

            as they become available, with the stream terminated by a `data:
            [DONE]` message.

            [Example Python
            code](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_stream_completions.ipynb).
          default: true
      required:
        - model
        - messages
    CreateChatCompletionResponse:
      type: object
      properties:
        id:
          type: string
          description: A unique identifier for the chat completion.
        object:
          type: string
          description: The object type, which is always `chat.completion`.
        created:
          type: integer
          format: unixtime
          description: >-
            The Unix timestamp (in seconds) of when the chat completion was
            created.
        model:
          type: string
          description: The model used for the chat completion.
        choices:
          type: array
          items:
            type: object
            properties:
              index:
                type: integer
                format: int64
                description: The index of the choice in the list of choices.
              message:
                $ref: '#/components/schemas/ChatCompletionResponseMessage'
              finish_reason:
                type: string
                enum:
                  - stop
                  - length
                  - function_call
                description: >-
                  The reason the model stopped generating tokens. This will be
                  `stop` if the model hit a

                  natural stop point or a provided stop sequence, `length` if
                  the maximum number of tokens

                  specified in the request was reached, or `function_call` if
                  the model called a function.
            required:
              - index
              - message
              - finish_reason
          description: >-
            A list of chat completion choices. Can be more than one if `n` is
            greater than 1.
        usage:
          $ref: '#/components/schemas/CompletionUsage'
      description: >-
        Represents a chat completion response returned by model, based on the
        provided input.
      required:
        - id
        - object
        - created
        - model
        - choices
      x-oaiMeta:
        name: The chat completion object
        group: chat
        example: ''
    CreateCompletionRequest:
      type: object
      properties:
        model:
          anyOf:
            - type: string
            - type: string
              enum:
                - babbage-002
                - davinci-002
                - text-davinci-003
                - text-davinci-002
                - text-davinci-001
                - code-davinci-002
                - text-curie-001
                - text-babbage-001
                - text-ada-001
          description: >-
            ID of the model to use. You can use the [List
            models](/docs/api-reference/models/list) API to

            see all of your available models, or see our [Model
            overview](/docs/models/overview) for

            descriptions of them.
          x-oaiTypeLabel: string
        prompt:
          anyOf:
            - type: string
            - type: array
              items:
                type: string
            - $ref: '#/components/schemas/TokenArray'
            - $ref: '#/components/schemas/TokenArrayArray'
          nullable: true
          description: >-
            The prompt(s) to generate completions for, encoded as a string,
            array of strings, array of

            tokens, or array of token arrays.


            Note that <|endoftext|> is the document separator that the model
            sees during training, so if a

            prompt is not specified the model will generate as if from the
            beginning of a new document.
          default: <|endoftext|>
        suffix:
          type: string
          nullable: true
          description: The suffix that comes after a completion of inserted text.
        temperature:
          oneOf:
            - $ref: '#/components/schemas/Temperature'
          nullable: true
          description: >-
            What sampling temperature to use, between 0 and 2. Higher values
            like 0.8 will make the output

            more random, while lower values like 0.2 will make it more focused
            and deterministic.


            We generally recommend altering this or `top_p` but not both.
        top_p:
          oneOf:
            - $ref: '#/components/schemas/TopP'
          nullable: true
          description: >-
            An alternative to sampling with temperature, called nucleus
            sampling, where the model considers

            the results of the tokens with top_p probability mass. So 0.1 means
            only the tokens comprising

            the top 10% probability mass are considered.


            We generally recommend altering this or `temperature` but not both.
        'n':
          oneOf:
            - $ref: '#/components/schemas/N'
          nullable: true
          description: >-
            How many completions to generate for each prompt.

            **Note:** Because this parameter generates many completions, it can
            quickly consume your token

            quota. Use carefully and ensure that you have reasonable settings
            for `max_tokens` and `stop`.
        max_tokens:
          oneOf:
            - $ref: '#/components/schemas/MaxTokens'
          nullable: true
          description: >-
            The maximum number of [tokens](/tokenizer) to generate in the
            completion.


            The token count of your prompt plus `max_tokens` cannot exceed the
            model's context length.

            [Example Python
            code](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb)

            for counting tokens.
        stop:
          anyOf:
            - type: string
            - $ref: '#/components/schemas/StopSequences'
          nullable: true
          description: Up to 4 sequences where the API will stop generating further tokens.
        presence_penalty:
          oneOf:
            - $ref: '#/components/schemas/Penalty'
          nullable: true
          description: >-
            Number between -2.0 and 2.0. Positive values penalize new tokens
            based on whether they appear

            in the text so far, increasing the model's likelihood to talk about
            new topics.


            [See more information about frequency and presence
            penalties.](/docs/guides/gpt/parameter-details)
        frequency_penalty:
          oneOf:
            - $ref: '#/components/schemas/Penalty'
          nullable: true
          description: >-
            Number between -2.0 and 2.0. Positive values penalize new tokens
            based on their existing

            frequency in the text so far, decreasing the model's likelihood to
            repeat the same line

            verbatim.


            [See more information about frequency and presence
            penalties.](/docs/guides/gpt/parameter-details)
        logit_bias:
          type: object
          additionalProperties:
            type: integer
            format: int64
          nullable: true
          description: >-
            Modify the likelihood of specified tokens appearing in the
            completion.

            Accepts a json object that maps tokens (specified by their token ID
            in the tokenizer) to an

            associated bias value from -100 to 100. Mathematically, the bias is
            added to the logits

            generated by the model prior to sampling. The exact effect will vary
            per model, but values

            between -1 and 1 should decrease or increase likelihood of
            selection; values like -100 or 100

            should result in a ban or exclusive selection of the relevant token.
          x-oaiTypeLabel: map
        user:
          allOf:
            - $ref: '#/components/schemas/User'
          description: >-
            A unique identifier representing your end-user, which can help
            OpenAI to monitor and detect

            abuse. [Learn
            more](/docs/guides/safety-best-practices/end-user-ids).
        stream:
          type: boolean
          nullable: true
          description: >-
            If set, partial message deltas will be sent, like in ChatGPT. Tokens
            will be sent as data-only

            [server-sent
            events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)

            as they become available, with the stream terminated by a `data:
            [DONE]` message.

            [Example Python
            code](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_stream_completions.ipynb).
          default: true
        logprobs:
          type: integer
          format: int64
          nullable: true
          description: >-
            Include the log probabilities on the `logprobs` most likely tokens,
            as well the chosen tokens.

            For example, if `logprobs` is 5, the API will return a list of the 5
            most likely tokens. The

            API will always return the `logprob` of the sampled token, so there
            may be up to `logprobs+1`

            elements in the response.


            The maximum value for `logprobs` is 5.
        echo:
          type: boolean
          nullable: true
          description: Echo back the prompt in addition to the completion
          default: false
        best_of:
          type: integer
          format: int64
          nullable: true
          description: >-
            Generates `best_of` completions server-side and returns the "best"
            (the one with the highest

            log probability per token). Results cannot be streamed.


            When used with `n`, `best_of` controls the number of candidate
            completions and `n` specifies

            how many to return – `best_of` must be greater than `n`.


            **Note:** Because this parameter generates many completions, it can
            quickly consume your token

            quota. Use carefully and ensure that you have reasonable settings
            for `max_tokens` and `stop`.
      required:
        - model
        - prompt
        - best_of
    CreateCompletionResponse:
      type: object
      properties:
        id:
          type: string
          description: A unique identifier for the completion.
        object:
          type: string
          description: The object type, which is always `text_completion`.
        created:
          type: integer
          format: unixtime
          description: The Unix timestamp (in seconds) of when the completion was created.
        model:
          type: string
          description: The model used for the completion.
        choices:
          type: array
          items:
            type: object
            properties:
              index:
                type: integer
                format: int64
              text:
                type: string
              logprobs:
                type: object
                properties:
                  tokens:
                    type: array
                    items:
                      type: string
                  token_logprobs:
                    type: array
                    items:
                      type: number
                      format: double
                  top_logprobs:
                    type: array
                    items:
                      type: object
                      additionalProperties:
                        type: integer
                        format: int64
                  text_offset:
                    type: array
                    items:
                      type: integer
                      format: int64
                required:
                  - tokens
                  - token_logprobs
                  - top_logprobs
                  - text_offset
                nullable: true
              finish_reason:
                type: string
                enum:
                  - stop
                  - length
                description: >-
                  The reason the model stopped generating tokens. This will be
                  `stop` if the model hit a

                  natural stop point or a provided stop sequence, or `length` if
                  the maximum number of tokens

                  specified in the request was reached.
            required:
              - index
              - text
              - logprobs
              - finish_reason
          description: The list of completion choices the model generated for the input.
        usage:
          $ref: '#/components/schemas/CompletionUsage'
      description: >-
        Represents a completion response from the API. Note: both the streamed
        and non-streamed response

        objects share the same shape (unlike the chat endpoint).
      required:
        - id
        - object
        - created
        - model
        - choices
      x-oaiMeta:
        name: The  completion object
        legacy: true
        example: ''
    CreateEditRequest:
      type: object
      properties:
        model:
          anyOf:
            - type: string
            - type: string
              enum:
                - text-davinci-edit-001
                - code-davinci-edit-001
          description: >-
            ID of the model to use. You can use the `text-davinci-edit-001` or
            `code-davinci-edit-001`

            model with this endpoint.
          x-oaiTypeLabel: string
        input:
          type: string
          nullable: true
          description: The input text to use as a starting point for the edit.
          default: ''
        instruction:
          type: string
          description: The instruction that tells the model how to edit the prompt.
        'n':
          oneOf:
            - $ref: '#/components/schemas/EditN'
          nullable: true
          description: How many edits to generate for the input and instruction.
        temperature:
          oneOf:
            - $ref: '#/components/schemas/Temperature'
          nullable: true
          description: >-
            What sampling temperature to use, between 0 and 2. Higher values
            like 0.8 will make the output

            more random, while lower values like 0.2 will make it more focused
            and deterministic.


            We generally recommend altering this or `top_p` but not both.
        top_p:
          oneOf:
            - $ref: '#/components/schemas/TopP'
          nullable: true
          description: >-
            An alternative to sampling with temperature, called nucleus
            sampling, where the model considers

            the results of the tokens with top_p probability mass. So 0.1 means
            only the tokens comprising

            the top 10% probability mass are considered.


            We generally recommend altering this or `temperature` but not both.
      required:
        - model
        - instruction
    CreateEditResponse:
      type: object
      properties:
        object:
          type: string
          enum:
            - edit
          description: The object type, which is always `edit`.
        created:
          type: integer
          format: unixtime
          description: The Unix timestamp (in seconds) of when the edit was created.
        choices:
          type: array
          items:
            type: object
            properties:
              text:
                type: string
                description: The edited result.
              index:
                type: integer
                format: int64
                description: The index of the choice in the list of choices.
              finish_reason:
                type: string
                enum:
                  - stop
                  - length
                description: >-
                  The reason the model stopped generating tokens. This will be
                  `stop` if the model hit a

                  natural stop point or a provided stop sequence, or `length` if
                  the maximum number of tokens

                  specified in the request was reached.
            required:
              - text
              - index
              - finish_reason
          description: >-
            description: A list of edit choices. Can be more than one if `n` is
            greater than 1.
        usage:
          $ref: '#/components/schemas/CompletionUsage'
      required:
        - object
        - created
        - choices
        - usage
    CreateEmbeddingRequest:
      type: object
      properties:
        model:
          anyOf:
            - type: string
            - type: string
              enum:
                - text-embedding-ada-002
          description: >-
            ID of the model to use. You can use the [List
            models](/docs/api-reference/models/list) API to see all of your
            available models, or see our [Model overview](/docs/models/overview)
            for descriptions of them.
          x-oaiTypeLabel: string
        input:
          anyOf:
            - type: string
            - type: array
              items:
                type: string
            - $ref: '#/components/schemas/TokenArray'
            - $ref: '#/components/schemas/TokenArrayArray'
          description: >-
            Input text to embed, encoded as a string or array of tokens. To
            embed multiple inputs in a

            single request, pass an array of strings or array of token arrays.
            Each input must not exceed

            the max input tokens for the model (8191 tokens for
            `text-embedding-ada-002`).

            [Example Python
            code](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb)

            for counting tokens.
        user:
          $ref: '#/components/schemas/User'
      required:
        - model
        - input
    CreateEmbeddingResponse:
      type: object
      properties:
        object:
          type: string
          enum:
            - embedding
          description: The object type, which is always "embedding".
        model:
          type: string
          description: The name of the model used to generate the embedding.
        data:
          type: array
          items:
            $ref: '#/components/schemas/Embedding'
          description: The list of embeddings generated by the model.
        usage:
          type: object
          properties:
            prompt_tokens:
              type: integer
              format: int64
              description: The number of tokens used by the prompt.
            total_tokens:
              type: integer
              format: int64
              description: The total number of tokens used by the request.
          description: The usage information for the request.
          required:
            - prompt_tokens
            - total_tokens
      required:
        - object
        - model
        - data
        - usage
    CreateFileRequest:
      type: object
      properties:
        file:
          type: string
          format: binary
          description: >-
            Name of the [JSON
            Lines](https://jsonlines.readthedocs.io/en/latest/) file to be
            uploaded.


            If the `purpose` is set to "fine-tune", the file will be used for
            fine-tuning.
        purpose:
          type: string
          description: >-
            The intended purpose of the uploaded documents. Use "fine-tune" for

            [fine-tuning](/docs/api-reference/fine-tuning). This allows us to
            validate the format of the

            uploaded file.
      required:
        - file
        - purpose
    CreateFineTuneRequest:
      type: object
      properties:
        training_file:
          type: string
          description: >-
            The ID of an uploaded file that contains training data.


            See [upload file](/docs/api-reference/files/upload) for how to
            upload a file.


            Your dataset must be formatted as a JSONL file, where each training
            example is a JSON object

            with the keys "prompt" and "completion". Additionally, you must
            upload your file with the

            purpose `fine-tune`.


            See the [fine-tuning
            guide](/docs/guides/legacy-fine-tuning/creating-training-data) for
            more

            details.
        validation_file:
          type: string
          nullable: true
          description: >-
            The ID of an uploaded file that contains validation data.


            If you provide this file, the data is used to generate validation
            metrics periodically during

            fine-tuning. These metrics can be viewed in the

            [fine-tuning results
            file](/docs/guides/legacy-fine-tuning/analyzing-your-fine-tuned-model).

            Your train and validation data should be mutually exclusive.


            Your dataset must be formatted as a JSONL file, where each
            validation example is a JSON object

            with the keys "prompt" and "completion". Additionally, you must
            upload your file with the

            purpose `fine-tune`.


            See the [fine-tuning
            guide](/docs/guides/legacy-fine-tuning/creating-training-data) for
            more

            details.
        model:
          anyOf:
            - type: string
            - type: string
              enum:
                - ada
                - babbage
                - curie
                - davinci
          nullable: true
          description: >-
            The name of the base model to fine-tune. You can select one of
            "ada", "babbage", "curie",

            "davinci", or a fine-tuned model created after 2022-04-21 and before
            2023-08-22. To learn more

            about these models, see the [Models](/docs/models) documentation.
          x-oaiTypeLabel: string
        n_epochs:
          type: integer
          format: int64
          nullable: true
          description: >-
            The number of epochs to train the model for. An epoch refers to one
            full cycle through the

            training dataset.
        batch_size:
          type: integer
          format: int64
          nullable: true
          description: >-
            The batch size to use for training. The batch size is the number of
            training examples used to

            train a single forward and backward pass.


            By default, the batch size will be dynamically configured to be
            ~0.2% of the number of examples

            in the training set, capped at 256 - in general, we've found that
            larger batch sizes tend to

            work better for larger datasets.
        learning_rate_multiplier:
          type: number
          format: double
          nullable: true
          description: >-
            The learning rate multiplier to use for training. The fine-tuning
            learning rate is the original

            learning rate used for pretraining multiplied by this value.


            By default, the learning rate multiplier is the 0.05, 0.1, or 0.2
            depending on final

            `batch_size` (larger learning rates tend to perform better with
            larger batch sizes). We

            recommend experimenting with values in the range 0.02 to 0.2 to see
            what produces the best

            results.
        prompt_loss_rate:
          type: number
          format: double
          nullable: true
          description: >-
            The weight to use for loss on the prompt tokens. This controls how
            much the model tries to

            learn to generate the prompt (as compared to the completion which
            always has a weight of 1.0),

            and can add a stabilizing effect to training when completions are
            short.


            If prompts are extremely long (relative to completions), it may make
            sense to reduce this

            weight so as to avoid over-prioritizing learning the prompt.
        compute_classification_metrics:
          type: boolean
          nullable: true
          description: >-
            If set, we calculate classification-specific metrics such as
            accuracy and F-1 score using the

            validation set at the end of every epoch. These metrics can be
            viewed in the

            [results
            file](/docs/guides/legacy-fine-tuning/analyzing-your-fine-tuned-model).


            In order to compute classification metrics, you must provide a
            `validation_file`. Additionally,

            you must specify `classification_n_classes` for multiclass
            classification or

            `classification_positive_class` for binary classification.
        classification_n_classes:
          type: integer
          format: int64
          nullable: true
          description: |-
            The number of classes in a classification task.

            This parameter is required for multiclass classification.
        classification_positive_class:
          type: string
          nullable: true
          description: >-
            The positive class in binary classification.


            This parameter is needed to generate precision, recall, and F1
            metrics when doing binary

            classification.
        classification_betas:
          type: array
          items:
            type: number
            format: double
          nullable: true
          description: >-
            If this is provided, we calculate F-beta scores at the specified
            beta values. The F-beta score

            is a generalization of F-1 score. This is only used for binary
            classification.


            With a beta of 1 (i.e. the F-1 score), precision and recall are
            given the same weight. A larger

            beta score puts more weight on recall and less on precision. A
            smaller beta score puts more

            weight on precision and less on recall.
        suffix:
          oneOf:
            - $ref: '#/components/schemas/SuffixString'
          nullable: true
          description: >-
            A string of up to 40 characters that will be added to your
            fine-tuned model name.


            For example, a `suffix` of "custom-model-name" would produce a model
            name like

            `ada:ft-your-org:custom-model-name-2022-02-15-04-21-04`.
      required:
        - training_file
        - suffix
    CreateFineTuningJobRequest:
      type: object
      properties:
        training_file:
          type: string
          description: >-
            The ID of an uploaded file that contains training data.


            See [upload file](/docs/api-reference/files/upload) for how to
            upload a file.


            Your dataset must be formatted as a JSONL file. Additionally, you
            must upload your file with

            the purpose `fine-tune`.


            See the [fine-tuning guide](/docs/guides/fine-tuning) for more
            details.
        validation_file:
          type: string
          nullable: true
          description: >-
            The ID of an uploaded file that contains validation data.


            If you provide this file, the data is used to generate validation
            metrics periodically during

            fine-tuning. These metrics can be viewed in the fine-tuning results
            file. The same data should

            not be present in both train and validation files.


            Your dataset must be formatted as a JSONL file. You must upload your
            file with the purpose

            `fine-tune`.


            See the [fine-tuning guide](/docs/guides/fine-tuning) for more
            details.
        model:
          anyOf:
            - type: string
            - type: string
              enum:
                - babbage-002
                - davinci-002
                - gpt-3.5-turbo
          description: >-
            The name of the model to fine-tune. You can select one of the

            [supported
            models](/docs/guides/fine-tuning/what-models-can-be-fine-tuned).
          x-oaiTypeLabel: string
        hyperparameters:
          type: object
          properties:
            n_epochs:
              anyOf:
                - type: string
                  enum:
                    - auto
                - $ref: '#/components/schemas/NEpochs'
              description: >-
                The number of epochs to train the model for. An epoch refers to
                one full cycle through the

                training dataset.
              default: auto
          description: The hyperparameters used for the fine-tuning job.
        suffix:
          oneOf:
            - $ref: '#/components/schemas/SuffixString'
          nullable: true
          description: >-
            A string of up to 40 characters that will be added to your
            fine-tuned model name.


            For example, a `suffix` of "custom-model-name" would produce a model
            name like

            `ft:gpt-3.5-turbo:openai:custom-model-name:7p4lURel`.
      required:
        - training_file
        - model
    CreateImageEditRequest:
      type: object
      properties:
        prompt:
          type: string
          description: >-
            A text description of the desired image(s). The maximum length is
            1000 characters.
        image:
          type: string
          format: binary
          description: >-
            The image to edit. Must be a valid PNG file, less than 4MB, and
            square. If mask is not

            provided, image must have transparency, which will be used as the
            mask.
        mask:
          type: string
          format: binary
          description: >-
            An additional image whose fully transparent areas (e.g. where alpha
            is zero) indicate where

            `image` should be edited. Must be a valid PNG file, less than 4MB,
            and have the same dimensions

            as `image`.
        'n':
          oneOf:
            - $ref: '#/components/schemas/ImagesN'
          nullable: true
          description: The number of images to generate. Must be between 1 and 10.
        size:
          type: string
          enum:
            - 256x256
            - 512x512
            - 1024x1024
          nullable: true
          description: >-
            The size of the generated images. Must be one of `256x256`,
            `512x512`, or `1024x1024`.
        response_format:
          type: string
          enum:
            - url
            - b64_json
          nullable: true
          description: >-
            The format in which the generated images are returned. Must be one
            of `url` or `b64_json`.
          default: url
        user:
          $ref: '#/components/schemas/User'
      required:
        - prompt
        - image
    CreateImageRequest:
      type: object
      properties:
        prompt:
          type: string
          description: >-
            A text description of the desired image(s). The maximum length is
            1000 characters.
        'n':
          oneOf:
            - $ref: '#/components/schemas/ImagesN'
          nullable: true
          description: The number of images to generate. Must be between 1 and 10.
        size:
          type: string
          enum:
            - 256x256
            - 512x512
            - 1024x1024
          nullable: true
          description: >-
            The size of the generated images. Must be one of `256x256`,
            `512x512`, or `1024x1024`.
        response_format:
          type: string
          enum:
            - url
            - b64_json
          nullable: true
          description: >-
            The format in which the generated images are returned. Must be one
            of `url` or `b64_json`.
          default: url
        user:
          $ref: '#/components/schemas/User'
      required:
        - prompt
    CreateImageVariationRequest:
      type: object
      properties:
        image:
          type: string
          format: binary
          description: >-
            The image to use as the basis for the variation(s). Must be a valid
            PNG file, less than 4MB,

            and square.
        'n':
          oneOf:
            - $ref: '#/components/schemas/ImagesN'
          nullable: true
          description: The number of images to generate. Must be between 1 and 10.
        size:
          type: string
          enum:
            - 256x256
            - 512x512
            - 1024x1024
          nullable: true
          description: >-
            The size of the generated images. Must be one of `256x256`,
            `512x512`, or `1024x1024`.
        response_format:
          type: string
          enum:
            - url
            - b64_json
          nullable: true
          description: >-
            The format in which the generated images are returned. Must be one
            of `url` or `b64_json`.
          default: url
        user:
          $ref: '#/components/schemas/User'
      required:
        - image
    CreateTranscriptionRequest:
      type: object
      properties:
        file:
          type: string
          format: binary
          description: >-
            The audio file object (not file name) to transcribe, in one of these
            formats: flac, mp3, mp4,

            mpeg, mpga, m4a, ogg, wav, or webm.
          x-oaiTypeLabel: file
        model:
          anyOf:
            - type: string
            - type: string
              enum:
                - whisper-1
          description: ID of the model to use. Only `whisper-1` is currently available.
          x-oaiTypeLabel: string
        prompt:
          type: string
          description: >-
            An optional text to guide the model's style or continue a previous
            audio segment. The

            [prompt](/docs/guides/speech-to-text/prompting) should match the
            audio language.
        response_format:
          type: string
          enum:
            - json
            - text
            - srt
            - verbose_json
            - vtt
          description: >-
            The format of the transcript output, in one of these options: json,
            text, srt, verbose_json, or

            vtt.
          default: json
        temperature:
          type: number
          format: double
          description: >-
            The sampling temperature, between 0 and 1. Higher values like 0.8
            will make the output more

            random, while lower values like 0.2 will make it more focused and
            deterministic. If set to 0,

            the model will use [log
            probability](https://en.wikipedia.org/wiki/Log_probability) to

            automatically increase the temperature until certain thresholds are
            hit.
          minimum: 0
          maximum: 1
        language:
          type: string
          description: >-
            The language of the input audio. Supplying the input language in

            [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes)
            format will improve accuracy

            and latency.
      required:
        - file
        - model
    CreateTranscriptionResponse:
      type: object
      properties:
        text:
          type: string
      required:
        - text
    CreateTranslationRequest:
      type: object
      properties:
        file:
          type: string
          format: binary
          description: >-
            The audio file object (not file name) to translate, in one of these
            formats: flac, mp3, mp4,

            mpeg, mpga, m4a, ogg, wav, or webm.
          x-oaiTypeLabel: file
        model:
          anyOf:
            - type: string
            - type: string
              enum:
                - whisper-1
          description: ID of the model to use. Only `whisper-1` is currently available.
          x-oaiTypeLabel: string
        prompt:
          type: string
          description: >-
            An optional text to guide the model's style or continue a previous
            audio segment. The

            [prompt](/docs/guides/speech-to-text/prompting) should match the
            audio language.
        response_format:
          type: string
          enum:
            - json
            - text
            - srt
            - verbose_json
            - vtt
          description: >-
            The format of the transcript output, in one of these options: json,
            text, srt, verbose_json, or

            vtt.
          default: json
        temperature:
          type: number
          format: double
          description: >-
            The sampling temperature, between 0 and 1. Higher values like 0.8
            will make the output more

            random, while lower values like 0.2 will make it more focused and
            deterministic. If set to 0,

            the model will use [log
            probability](https://en.wikipedia.org/wiki/Log_probability) to

            automatically increase the temperature until certain thresholds are
            hit.
          minimum: 0
          maximum: 1
      required:
        - file
        - model
    CreateTranslationResponse:
      type: object
      properties:
        text:
          type: string
      required:
        - text
    DeleteFileResponse:
      type: object
      properties:
        id:
          type: string
        object:
          type: string
        deleted:
          type: boolean
      required:
        - id
        - object
        - deleted
    EditN:
      type: integer
      format: int64
      minimum: 0
      maximum: 20
    Embedding:
      type: object
      properties:
        index:
          type: integer
          format: int64
          description: The index of the embedding in the list of embeddings.
        object:
          type: string
          enum:
            - embedding
          description: The object type, which is always "embedding".
        embedding:
          type: array
          items:
            type: number
            format: double
          description: >-
            The embedding vector, which is a list of floats. The length of
            vector depends on the model as\

            listed in the [embedding guide](/docs/guides/embeddings).
      description: Represents an embedding vector returned by embedding endpoint.
      required:
        - index
        - object
        - embedding
    FineTune:
      type: object
      properties:
        id:
          type: string
          description: The object identifier, which can be referenced in the API endpoints.
        object:
          type: string
          enum:
            - fine-tune
          description: The object type, which is always "fine-tune".
        created_at:
          type: integer
          format: unixtime
          description: >-
            The Unix timestamp (in seconds) for when the fine-tuning job was
            created.
        updated_at:
          type: integer
          format: unixtime
          description: >-
            The Unix timestamp (in seconds) for when the fine-tuning job was
            last updated.
        model:
          type: string
          description: The base model that is being fine-tuned.
        fine_tuned_model:
          type: string
          nullable: true
          description: The name of the fine-tuned model that is being created.
        organization_id:
          type: string
          description: The organization that owns the fine-tuning job.
        status:
          type: string
          enum:
            - created
            - running
            - succeeded
            - failed
            - cancelled
          description: >-
            The current status of the fine-tuning job, which can be either
            `created`, `running`,

            `succeeded`, `failed`, or `cancelled`.
        hyperparams:
          type: object
          properties:
            n_epochs:
              type: integer
              format: int64
              description: >-
                The number of epochs to train the model for. An epoch refers to
                one full cycle through the

                training dataset.
            batch_size:
              type: integer
              format: int64
              description: >-
                The batch size to use for training. The batch size is the number
                of training examples used to

                train a single forward and backward pass.
            prompt_loss_weight:
              type: number
              format: double
              description: The weight to use for loss on the prompt tokens.
            learning_rate_multiplier:
              type: number
              format: double
              description: The learning rate multiplier to use for training.
            compute_classification_metrics:
              type: boolean
              description: >-
                The classification metrics to compute using the validation
                dataset at the end of every epoch.
            classification_positive_class:
              type: string
              description: The positive class to use for computing classification metrics.
            classification_n_classes:
              type: integer
              format: int64
              description: >-
                The number of classes to use for computing classification
                metrics.
          description: >-
            The hyperparameters used for the fine-tuning job. See the

            [fine-tuning guide](/docs/guides/legacy-fine-tuning/hyperparameters)
            for more details.
          required:
            - n_epochs
            - batch_size
            - prompt_loss_weight
            - learning_rate_multiplier
        training_files:
          type: array
          items:
            $ref: '#/components/schemas/OpenAIFile'
          description: The list of files used for training.
        validation_files:
          type: array
          items:
            $ref: '#/components/schemas/OpenAIFile'
          description: The list of files used for validation.
        result_files:
          type: array
          items:
            $ref: '#/components/schemas/OpenAIFile'
          description: The compiled results files for the fine-tuning job.
        events:
          type: array
          items:
            $ref: '#/components/schemas/FineTuneEvent'
          description: >-
            The list of events that have been observed in the lifecycle of the
            FineTune job.
      description: >-
        The `FineTune` object represents a legacy fine-tune job that has been
        created through the API.
      required:
        - id
        - object
        - created_at
        - updated_at
        - model
        - fine_tuned_model
        - organization_id
        - status
        - hyperparams
        - training_files
        - validation_files
        - result_files
    FineTuneEvent:
      type: object
      properties:
        object:
          type: string
        created_at:
          type: integer
          format: unixtime
        level:
          type: string
        message:
          type: string
      required:
        - object
        - created_at
        - level
        - message
    FineTuningEvent:
      type: object
      properties:
        object:
          type: string
        created_at:
          type: integer
          format: unixtime
        level:
          type: string
        message:
          type: string
        data:
          type: object
          additionalProperties: {}
          nullable: true
        type:
          type: string
          enum:
            - message
            - metrics
      required:
        - object
        - created_at
        - level
        - message
    FineTuningJob:
      type: object
      properties:
        id:
          type: string
          description: The object identifier, which can be referenced in the API endpoints.
        object:
          type: string
          enum:
            - fine_tuning.job
          description: The object type, which is always "fine_tuning.job".
        created_at:
          type: integer
          format: unixtime
          description: >-
            The Unix timestamp (in seconds) for when the fine-tuning job was
            created.
        finished_at:
          type: integer
          format: unixtime
          description: >-
            The Unix timestamp (in seconds) for when the fine-tuning job was
            finished.
        model:
          type: string
          description: The base model that is being fine-tuned.
        fine_tuned_model:
          type: string
          nullable: true
          description: The name of the fine-tuned model that is being created.
        organization_id:
          type: string
          description: The organization that owns the fine-tuning job.
        status:
          type: string
          enum:
            - created
            - pending
            - running
            - succeeded
            - failed
            - cancelled
          description: >-
            The current status of the fine-tuning job, which can be either
            `created`, `pending`, `running`,

            `succeeded`, `failed`, or `cancelled`.
        hyperparameters:
          type: object
          properties:
            n_epochs:
              anyOf:
                - type: string
                  enum:
                    - auto
                - $ref: '#/components/schemas/NEpochs'
              description: >-
                The number of epochs to train the model for. An epoch refers to
                one full cycle through the

                training dataset.


                "Auto" decides the optimal number of epochs based on the size of
                the dataset. If setting the

                number manually, we support any number between 1 and 50 epochs.
              default: auto
          description: |-
            The hyperparameters used for the fine-tuning job. See the
            [fine-tuning guide](/docs/guides/fine-tuning) for more details.
        training_file:
          type: string
          description: The file ID used for training.
        validation_file:
          type: string
          nullable: true
          description: The file ID used for validation.
        result_files:
          type: array
          items:
            $ref: '#/components/schemas/OpenAIFile'
          description: The compiled results files for the fine-tuning job.
        trained_tokens:
          type: integer
          format: int64
          description: >-
            The total number of billable tokens processed by this fine tuning
            job.
      required:
        - id
        - object
        - created_at
        - finished_at
        - model
        - fine_tuned_model
        - organization_id
        - status
        - hyperparameters
        - training_file
        - validation_file
        - result_files
        - trained_tokens
    FineTuningJobEvent:
      type: object
      properties:
        object:
          type: string
        created_at:
          type: integer
          format: unixtime
        level:
          type: string
          enum:
            - info
            - warn
            - error
        message:
          type: string
      required:
        - object
        - created_at
        - level
        - message
    Image:
      type: object
      properties:
        url:
          type: string
          format: uri
          description: >-
            The URL of the generated image, if `response_format` is `url`
            (default).
        b64_json:
          type: string
          format: base64
          description: >-
            The base64-encoded JSON of the generated image, if `response_format`
            is `b64_json`.
      description: >-
        Represents the url or the content of an image generated by the OpenAI
        API.
    ImagesN:
      type: integer
      format: int64
      minimum: 1
      maximum: 10
    ImagesResponse:
      type: object
      properties:
        created:
          type: integer
          format: unixtime
        data:
          type: array
          items:
            $ref: '#/components/schemas/Image'
      required:
        - created
        - data
    ListFilesResponse:
      type: object
      properties:
        object:
          type: string
        data:
          type: array
          items:
            $ref: '#/components/schemas/OpenAIFile'
      required:
        - object
        - data
    ListFineTuneEventsResponse:
      type: object
      properties:
        object:
          type: string
        data:
          type: array
          items:
            $ref: '#/components/schemas/FineTuneEvent'
      required:
        - object
        - data
    ListFineTunesResponse:
      type: object
      properties:
        object:
          type: string
        data:
          type: array
          items:
            $ref: '#/components/schemas/FineTune'
      required:
        - object
        - data
    ListFineTuningJobEventsResponse:
      type: object
      properties:
        object:
          type: string
        data:
          type: array
          items:
            $ref: '#/components/schemas/FineTuningJobEvent'
      required:
        - object
        - data
    ListPaginatedFineTuningJobsResponse:
      type: object
      properties:
        object:
          type: string
        data:
          type: array
          items:
            $ref: '#/components/schemas/FineTuningJob'
        has_more:
          type: boolean
      required:
        - object
        - data
        - has_more
    LogProbs:
      type: integer
      format: int64
      minimum: 0
      maximum: 5
    MaxTokens:
      type: integer
      format: int64
      minimum: 0
    'N':
      type: integer
      format: int64
      minimum: 1
      maximum: 128
    NEpochs:
      type: integer
      format: int64
      minimum: 1
      maximum: 50
    OpenAIFile:
      type: object
      properties:
        id:
          type: string
          description: The file identifier, which can be referenced in the API endpoints.
        object:
          type: string
          enum:
            - file
          description: The object type, which is always "file".
        bytes:
          type: integer
          format: int64
          description: The size of the file in bytes.
        createdAt:
          type: integer
          format: unixtime
          description: The Unix timestamp (in seconds) for when the file was created.
        filename:
          type: string
          description: The name of the file.
        purpose:
          type: string
          description: >-
            The intended purpose of the file. Currently, only "fine-tune" is
            supported.
        status:
          type: string
          enum:
            - uploaded
            - processed
            - pending
            - error
            - deleting
            - deleted
          description: >-
            The current status of the file, which can be either `uploaded`,
            `processed`, `pending`,

            `error`, `deleting` or `deleted`.
        status_details:
          type: string
          nullable: true
          description: >-
            Additional details about the status of the file. If the file is in
            the `error` state, this will

            include a message describing the error.
      description: >-
        The `File` object represents a document that has been uploaded to
        OpenAI.
      required:
        - id
        - object
        - bytes
        - createdAt
        - filename
        - purpose
        - status
    Penalty:
      type: number
      format: double
      minimum: -2
      maximum: 2
    StopSequences:
      type: array
      items:
        type: string
      minItems: 1
      maxItems: 4
    SuffixString:
      type: string
      minLength: 1
      maxLength: 40
    Temperature:
      type: number
      format: double
      minimum: 0
      maximum: 2
    TokenArray:
      type: array
      items:
        type: integer
        format: int64
      minItems: 1
    TokenArrayArray:
      type: array
      items:
        $ref: '#/components/schemas/TokenArray'
      minItems: 1
    TopP:
      type: number
      format: double
      minimum: 0
      maximum: 1
    User:
      type: string
